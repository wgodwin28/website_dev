---
title: "Fires Trend Analysis"
author: "Will Godwin"
date: "10/4/2019"
output: html_document
---

Purpose of the post: dissect the trend in number of large-scale fires from 1992-2015 at the state-level. Then potentally aggregate up to national level to determine national trend

Main components of time-series analysis:
Overall trend analysis
Seasonality
Cycle analysis

Steps to the analysis:
1. Figuring out temporal range of the response variable (daily, weekly, monthly-likely, or yearly)-show time series of each
2. 


A time series is a metric that's measured over regular intervals. Within the fires dataset, we can create a 
time series by aggregating a metric, like number of fires burning >100 acres, across a sensible time interval.
The purpose of this post is to decompose our time series of fire counts and identify its constituent patterns in an effort to understand the underlying data-generating process. The 3 main patterns we'll examine, and standard in time series analysis, is trend-cycle patterns, seasonal patterns, and the remainder component (anything not contained in first two components). Detailed explanations of these components are beyond the scope of this post but can be found [here](https://otexts.com/fpp2/decomposition.html). Detecting the strength to which each of these components influence our data can be useful from a policy perspective. For example, if we found a strong seasonal trend in wild fire counts (very likely!), fire-fighting agencies could make sure to prioritize resources within those high fire seasons and hold back otherwise.

Here, I decompose a time series of wild fire counts into 3 parts: trend-cycle component, seasonal component, and a remainder component. I predict to see an overall trend of increasing wild fires from 1992-2015. Additionally, I expect to see a strong seasonal pattern (intially substantiated in my previous [post](ca_fires_map.html)), with the majority of wild fires starting in summer months.


First, to create a metric with regular intervals, we'll need to decide on the time window for aggregation (by day, week, month, season, year?). This decision will be made by visual assessment of observed trend. I'll test aggregation by day, week, month, season, and year.

```{r, message=F, include=F}
#Purpose: make map of california fires in 2015 using leaflet
#https://medium.com/civis-analytics/making-interactive-maps-of-public-data-in-r-d360c0e13f13 based on this article

# clear memory
rm(list=ls())

#necessary libs
library(RSQLite); library(tidyverse); library(sf); library(leaflet); library(viridis)

#Read in wildfire data-it's in SQLite format so we'll query the local db
fires <- read.csv("~/Desktop/fires/data/fires_ca.csv")
#db <- dbConnect(SQLite(), dbname="~/Desktop/fires/data/FPA_FOD_20170508.sqlite")
#fires <- dbGetQuery(db, "SELECT * FROM Fires")

fires %>%
  filter(FIRE_SIZE>=100) %>%
  mutate(startDate=as.Date(paste0(FIRE_YEAR, "-", DISCOVERY_DOY), format="%Y-%j"), #make date variable
         month1=as.Date(paste0(FIRE_YEAR, "-", month(startDate),"-01"),"%Y-%m-%d")
         #month2=month(startDate),
  ) %>% #make month variable
  group_by(month1, FIRE_YEAR) %>%
  count()
  ggplot() +
  

```
Online textbooks and articles that aided in writing this post:
https://blogs.oracle.com/datascience/introduction-to-forecasting-with-arima-in-r (ARIMA)
https://otexts.com/fpp2/bottom-up.html (application in R-advanced methods)
https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322 (stationarity)